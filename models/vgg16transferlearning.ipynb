{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "178154c1909b80602abc389b22f18688830e8320"
   },
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, fnmatch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils, plot_model, to_categorical\n",
    "from keras.layers import Maximum, ZeroPadding2D, BatchNormalization\n",
    "from keras.layers import Input, Dense, Flatten, Activation, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import optimizers, regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "\n",
    "from keras import applications\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "750898e44f217002c23d730ef2ba9bacf00fc160"
   },
   "source": [
    "### Set variables for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Files Base Folder: TrainTestImages\n"
     ]
    }
   ],
   "source": [
    "## Set local variables\n",
    "labelCode = {}\n",
    "trainImage = []\n",
    "testImage = []\n",
    "allImages = []\n",
    "\n",
    "rows = 256\n",
    "cols = 256\n",
    "channels = 3\n",
    "\n",
    "## Set the path from where images needs to be read\n",
    "inputFileFolder = \"TrainTestImages\"\n",
    "print('Input Files Base Folder: %s' %(inputFileFolder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f997fcdcc7426fa2acd8e5b8a4bf87d6bec2a0a8"
   },
   "source": [
    "## Read all the folders/files present in input location and create training/test list having URL of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "6d35292f73730247684c04be886669b24bda0f77"
   },
   "outputs": [],
   "source": [
    "## lop through all the files and sub-folders\n",
    "for root, dirs, files in os.walk(inputFileFolder):\n",
    "    \n",
    "    file=[]\n",
    "    ## Read images and convert the same into array, also fetch/set their label\n",
    "    for f in files:\n",
    "        img = imageio.imread(os.path.join(root,f))\n",
    "        \n",
    "        ## If image is  a gray scale image, ignore that image\n",
    "        if(len(img.shape)!=3):\n",
    "            continue\n",
    "        \n",
    "        ## Set the directory elements\n",
    "        file.append(os.path.join(root,f))\n",
    "        allImages.append(os.path.join(root,f))\n",
    "                \n",
    "    if(file!=[]):\n",
    "        ## Create/update label dictionary\n",
    "        if(dirs == []):\n",
    "            imageLabel = os.path.basename(os.path.normpath(root))\n",
    "            if imageLabel not in labelCode:\n",
    "                labelCode[imageLabel] = len(labelCode)\n",
    "        \n",
    "        ## Shuffle the image URL's to split in train and test data\n",
    "        shuffle(file)\n",
    "        idxTrain = int(len(file) * 0.7)\n",
    "        trainImage.extend(file[:idxTrain])\n",
    "        testImage.extend(file[idxTrain:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88ba1a2b3329da5d70b764777e9163a3c55181f7"
   },
   "source": [
    "### Count the number of images in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c2191c046d68eb6da59b41db11526568e563e3b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: 19341, Test Images: 8304\n",
      "Total (27645): 27645\n"
     ]
    }
   ],
   "source": [
    "cntTestImages = len(testImage)\n",
    "cntTrainImages = len(trainImage)\n",
    "\n",
    "print('Train Images: %s, Test Images: %s' % (str(cntTrainImages), str(cntTestImages)))\n",
    "print('Total (%s): %s' %(str(len(allImages)), str(cntTestImages + cntTrainImages)))\n",
    "#testImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6f5bf480b76c4c4c98be0136d8b48ba23daa2f8"
   },
   "source": [
    "## Create methods for Image reading and model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "00c2c30e2feff9bb53270a7bc89d12e93cd072b2"
   },
   "outputs": [],
   "source": [
    "def getImageAndLabels(lsImagePath):\n",
    "    ''' This method is used to read the image from the given path and perform following action:\n",
    "        1. Conver image to array\n",
    "        2. Set the label and lable code for the image based on image path\n",
    "    '''\n",
    "    lsImageData = []\n",
    "    lsImageClass = []\n",
    "    lsImageLabel = []\n",
    "    \n",
    "    for path in lsImagePath:\n",
    "        img = imageio.imread(path)\n",
    "        ## If image is  a gray scale image, ignore that image\n",
    "        if(len(img.shape)!=3):\n",
    "            continue\n",
    "        \n",
    "        ## Set the directory elements\n",
    "        imgPath, filename = os.path.split(path)\n",
    "        ## basename returns the directory in which file is present and \n",
    "        ## normpath is used to remove slashes at the end\n",
    "        imageLabel = os.path.basename(os.path.normpath(imgPath))\n",
    "        \n",
    "        ## Add image array to the list\n",
    "        lsImageData.append(img)\n",
    "        ## Add image label code to the list\n",
    "        lsImageClass.append(labelCode[imageLabel])\n",
    "        ## Add image label desc to the list\n",
    "        lsImageLabel.append(imageLabel)\n",
    "        \n",
    "    return (lsImageData, lsImageClass, lsImageLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82ebd6188a1b523c5012274c0dfc1e3174c95bb2"
   },
   "source": [
    "### Methods for creating CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d9cc5efc1499cce65c7c4df6a9fea27c6d90d838"
   },
   "outputs": [],
   "source": [
    "# Dense layers set\n",
    "def dense_set(inp_layer, n, activation, drop_rate=0):\n",
    "    dp = Dropout(drop_rate)(inp_layer)\n",
    "    dns = Dense(n)(dp)\n",
    "    bn = BatchNormalization(axis=-1)(dns)\n",
    "    act = Activation(activation=activation)(bn)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c8046464defc90b36b467d792eb036a8c84ebc62"
   },
   "outputs": [],
   "source": [
    "# Conv. layers set\n",
    "def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), padding='same'):\n",
    "    conv = Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides, \n",
    "                  padding=padding)(feature_batch)\n",
    "    bn = BatchNormalization(axis=3)(conv)\n",
    "    act = ReLU()(bn) #LeakyReLU(1/10)(bn)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b21f740350a6f6b353abbaa5d938aaa135732a3d"
   },
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "8f4d9a24fc4e9b5e5f67bf224c19d062dc861db0"
   },
   "outputs": [],
   "source": [
    "def get10LayerModel(myoptim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)):\n",
    "    inp_img = Input(shape=(256, 256, 3))\n",
    "    conv1 = conv_layer(inp_img, 64)\n",
    "    conv2 = conv_layer(conv1, 64)\n",
    "    mp1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n",
    "    conv3 = conv_layer(mp1, 128)\n",
    "    conv4 = conv_layer(conv3, 128)\n",
    "    mp2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv4)\n",
    "    conv5 = conv_layer(mp2, 256)\n",
    "    conv6 = conv_layer(conv5, 256)\n",
    "    conv7 = conv_layer(conv6, 256)\n",
    "    mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv7)\n",
    "\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp3)\n",
    "    ds1 = dense_set(flt, 128, activation='relu') ## Changed it from 128 to 512\n",
    "    #ds2 = dense_set(ds1, 512, activation='relu') ## Added this layer\n",
    "    out = dense_set(ds1, num_classes, activation='softmax')\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=myoptim, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1c447168e455b48c709cf620b2f56e1139cb0827"
   },
   "outputs": [],
   "source": [
    "def get6LayerModel(myoptim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)):\n",
    "    inp_img = Input(shape=(256, 256, 3))\n",
    "    conv1 = conv_layer(inp_img, 32, padding='same')\n",
    "    mp1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv1)\n",
    "    conv2 = conv_layer(mp1, 64, padding='same')\n",
    "    mp2 = MaxPooling2D(pool_size=(5, 5), strides=(2, 2))(conv2)\n",
    "    conv3 = conv_layer(mp2, 128)\n",
    "    mp3 = MaxPooling2D(pool_size=(5, 5), strides=(2, 2))(conv3)\n",
    "    conv4 = conv_layer(mp3, 256)\n",
    "    mp4 = MaxPooling2D(pool_size=(7, 7), strides=(2, 2))(conv4)\n",
    "\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp4)\n",
    "    ds1 = dense_set(flt, 64, activation='relu')\n",
    "    ds2 = dense_set(ds1, 128, activation='relu')\n",
    "    out = dense_set(ds2, num_classes, activation='softmax')\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=myoptim, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "42d8a5ef10bdfb563a3b496b027642195857e2be"
   },
   "outputs": [],
   "source": [
    "# simple model \n",
    "def getSimpleModel(myoptim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)):\n",
    "    inp_img = Input(shape=(256, 256, 3))\n",
    "    conv1 = conv_layer(inp_img, 32)\n",
    "    mp1 = MaxPooling2D(pool_size=(4, 4))(conv1)\n",
    "    \n",
    "    # dense layers\n",
    "    flt = Flatten()(mp1)\n",
    "    ds1 = dense_set(flt, 256, activation='relu')\n",
    "    out = dense_set(ds1, num_classes, activation='softmax')\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=myoptim,\n",
    "                   metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e20f25685e08c224008e000dcdd3741ac21ae7ee"
   },
   "outputs": [],
   "source": [
    "def trainAndPredictModel(model, x_train, x_test, y_train, y_test, epochs=50, batchSize=16):\n",
    "    ''' This method is used to train and test the model and it also creates the confusion matrix'''\n",
    "    \n",
    "    ## Training and validating the model\n",
    "    model.fit(x= x_train, y=y_train, epochs=epochs, batch_size=batchSize, verbose=2, shuffle=True)\n",
    "    acc = model.evaluate(X_test,y_test)\n",
    "    print(\"=====================================================================================\")\n",
    "    print(\"Accuracy of the model: %s\" %(str(acc)))\n",
    "    print(\"=====================================================================================\")\n",
    "    \n",
    "    ## Creating confusion matrix and heat-map\n",
    "    ypred = np.zeros((y_test.shape))\n",
    "    y_predict = model.predict(x_test)\n",
    "    for idx, val in enumerate(y_predict):\n",
    "        ypred[idx, np.argmax(val)] = 1\n",
    "\n",
    "    return (model, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "59df8f7559b051d041a9f5bb6eaacab74bb1fba6"
   },
   "outputs": [],
   "source": [
    "def createConfusionMatrix(y_test, y_pred):\n",
    "    cr = metrics.classification_report(y_test,y_pred)\n",
    "    print(cr)\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test.argmax(axis=1), ypred.argmax(axis=1))\n",
    "    #print(cm)    \n",
    "    dfCM = pd.DataFrame(cm, index=list(labelCode), columns=list(labelCode))\n",
    "    plt.figure(figsize=(80,20))\n",
    "    ax = sns.heatmap(dfCM,vmax=8, square=True, fmt='.2f',annot=True, \n",
    "                     linecolor='white', linewidths=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88c929c388c2b9663c6963d8cc9c13b07a57c2d3"
   },
   "source": [
    "## Based on train/test URL, fetching the image array and corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "744799b3ffbd9cc8a9459e85b16a45958102d46f"
   },
   "outputs": [],
   "source": [
    "xtrain, ytrain, lbl_train = getImageAndLabels(trainImage)\n",
    "xtest, ytest, lbl_test = getImageAndLabels(testImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "732ea085347fa9d5292c958734dc19fb1d74152f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape:(19341, 256, 256, 3)\n",
      "X_Test Shape:(8304, 256, 256, 3)\n",
      "Y_Train Shape:(19341, 22)\n",
      "Y_Test Shape:(8304, 22)\n",
      "Number of classes:22\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(xtrain)\n",
    "y_train = np_utils.to_categorical(np.array(ytrain))\n",
    "X_test = np.asarray(xtest)\n",
    "y_test = np_utils.to_categorical(np.array(ytest))\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "## conver to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "##data needs to be normalized from 0\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print(\"X_Train Shape:%s\" %(str(X_train.shape)))\n",
    "print(\"X_Test Shape:%s\" %(str(X_test.shape)))\n",
    "print(\"Y_Train Shape:%s\" %(str(y_train.shape)))\n",
    "print(\"Y_Test Shape:%s\" %(str(y_test.shape)))\n",
    "print(\"Number of classes:%s\" %(str(num_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22746178a09f0cbd2a2a4dfcd59234e7f2ba0110"
   },
   "source": [
    "### Randomly viewing the train image and corresponding label for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5414f249523d2d34bb43139c5df9f28ef5183b4"
   },
   "outputs": [],
   "source": [
    "idx = 1380\n",
    "print(\"Label:%s, ClassCode:%s, Encoding:%s\" %(lbl_train[idx], ytrain[idx], y_train[idx]))\n",
    "plt.imshow(X_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08f01f4ebf16897fbbec0094d99f16234132e538"
   },
   "source": [
    "## Running various models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "522f02c075d3f46872c465e629a27fc6261e472b"
   },
   "source": [
    "### Running simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f207b4e200f1c1c381989037950317c0ff9e4bfa"
   },
   "outputs": [],
   "source": [
    "model1 = getSimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "707d389dfd705a9daadae12e7ebe8d1f2cb3dc46"
   },
   "outputs": [],
   "source": [
    "_, ypred = trainAndPredictModel(model1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98912f700c103763943ec5f2dd40e67fcff1a454"
   },
   "outputs": [],
   "source": [
    "createConfusionMatrix(y_test, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92fb2978b0129a328a881a5cf71b29371435fa19"
   },
   "source": [
    "#### Viewing random predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dede7f185725cc158a31bb4d951450e35faf3777"
   },
   "outputs": [],
   "source": [
    "idx = 160\n",
    "print(\"Predicted value: %s\" %(ypred[idx]))\n",
    "print(\"Actual value: %s\" %(y_test[idx]))\n",
    "print(labelCode)\n",
    "plt.imshow(X_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3715deb7df00ed60d0c1aa03c3dc1e3282461898"
   },
   "source": [
    "### Running simple model with diff learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ee8343664a9a9aeb82cfc69684ec1538530b83b"
   },
   "outputs": [],
   "source": [
    "model2 = getSimpleModel(optimizers.SGD(lr=0.0001, momentum=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3cea4784e91d534ea8ca753db6bc307887c620c2"
   },
   "outputs": [],
   "source": [
    "_, ypred = trainAndPredictModel(model2, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f219ff739095018498a4949f478dfa57d201eb4b"
   },
   "outputs": [],
   "source": [
    "createConfusionMatrix(y_test, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77d59a914357b01567dd720227b2a84442c1cc54"
   },
   "source": [
    "> ### Running 6 layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5de2006a0c4da1fc841c121d69553ec3d313e291"
   },
   "outputs": [],
   "source": [
    "model3 = get6LayerModel(myoptim='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a0f047d12173eea517fda15ddfb810b8e762a58"
   },
   "outputs": [],
   "source": [
    "_, ypred = trainAndPredictModel(model3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11404abd11a382ce1234c61fedcf361ea84b9bb5"
   },
   "outputs": [],
   "source": [
    "createConfusionMatrix(y_test, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f8d5091f4157d306149a864c90a089709f99768"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb93a6f49eab0d7b9db282ce4910d443b0feb893"
   },
   "outputs": [],
   "source": [
    "def createTransferModel(base_model, freezeLayers=10, \n",
    "                        optimizer = optimizers.SGD(lr=0.0001, momentum=0.9)):\n",
    "    # Freeze the layers which you don't want to train. Here I am freezing the first 10 layers.\n",
    "    for layer in base_model.layers[:freezeLayers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #Adding custom Layers \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # creating the final model \n",
    "    model_final = Model(input = base_model.input, output = predictions)\n",
    "\n",
    "    # compile the model \n",
    "    model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                        optimizer = optimizer,    \n",
    "                        metrics=[\"accuracy\"])\n",
    "\n",
    "    model_final.summary()\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e1474b514eaf59901cd8ba733adf56e4ade90b0"
   },
   "outputs": [],
   "source": [
    "# Fetch the base pre-trained model for creating new model\n",
    "#base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (rows, cols, channels))\n",
    "base_model = applications.VGG16(weights = \"imagenet\",include_top=False, \n",
    "                                input_shape = (rows, cols, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfe014e0c0da57ea84129e699c0594dab7d15296"
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8a02e66ac6f4234773898320975af98c100139d"
   },
   "outputs": [],
   "source": [
    "premodel = createTransferModel(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12a0bcbd7ce35d145d41bd881d2091060c8f0ecb"
   },
   "outputs": [],
   "source": [
    "_, ypred = trainAndPredictModel(premodel, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53a1dabcdc1acc57d33e39a3089f5e10465287b0"
   },
   "outputs": [],
   "source": [
    "createConfusionMatrix(y_test, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ad754638660fe6b904ef128ccac686a64b4a2ea"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
